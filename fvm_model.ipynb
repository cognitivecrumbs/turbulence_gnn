{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ea7b9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eb83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import *\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397ddaa",
   "metadata": {},
   "source": [
    "\n",
    "$\\frac{\\partial u_i}{\\partial t} = - \\frac{d p}{\\rho d x_i} - u_j \\frac{\\partial u_i}{\\partial x_j} + \\frac{1}{Re} \\frac{\\partial^2 u_j}{\\partial x_i \\partial x_j}$\n",
    "\n",
    "\n",
    "$\\frac{du_i}{dx_i} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e4e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3*a**3 - b**2\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "\n",
    "\n",
    "test = torch.arange(10,dtype=torch.float, requires_grad=True)\n",
    "external_grad = torch.tensor([0.5]*10)\n",
    "\n",
    "grad = test.backward(gradient=external_grad)\n",
    "print(test.grad)\n",
    "\n",
    "# simple biquadratic approximation for unstructured derivitive calculation\n",
    "# value = a0+a1x+a2x^2+a3y+a4y^2+a5xy\n",
    "\n",
    "# construct matrix\n",
    "coeff_mat = torch.empty(6*nodes*2,6*nodes*2)\n",
    "coeff_mat[:,0] = 0\n",
    "\n",
    "coeff_mat[:,1] = e[]\n",
    "\n",
    "loss = dudx+dvdy\n",
    "loss.backward()\n",
    "# update to p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad615f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FD(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def forward(self, v: torch.Tensor, e: torch.Tensor, ij: torch.Tensor) -> torch.Tensor:\n",
    "        # v stores [u,v]\n",
    "        # ij stores connections\n",
    "        # e stores [x_rel,y_rel]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FD(torch.nn.Module):\n",
    "    def __init__(self, dt: float = 0.01, rho: float = 1.0, nu: float = 0.01, relaxation_factor: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.dt = dt\n",
    "        self.nu = nu\n",
    "        self.rho = rho\n",
    "        self.relaxation_factor = relaxation_factor\n",
    "\n",
    "    def forward(self, v: torch.Tensor, e: torch.Tensor, ij: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        v: [N, 2] -> Velocity (u, v) at N nodes.\n",
    "        e: [M, 2] -> Relative distances (dx, dy) for M edges.\n",
    "        ij: [2, M] -> Connectivity (source i, neighbor j).\n",
    "        \"\"\"\n",
    "        num_nodes = v.size(0)\n",
    "        idx_i, idx_j = ij[0], ij[1]\n",
    "\n",
    "        # 1. Compute Differences (Message Passing)\n",
    "        # dv[m] = v[j] - v[i] for edge m\n",
    "        dv = v[idx_j] - v[idx_i]  # [M, 2]\n",
    "\n",
    "        # 2. Gradient Reconstruction (Least Squares / Weighted Avg)\n",
    "        # We approximate (du/dx, du/dy) and (dv/dx, dv/dy) at each edge\n",
    "        dist_sq = torch.sum(e**2, dim=1, keepdim=True) + 1e-8\n",
    "        \n",
    "        # Local directional derivatives per edge\n",
    "        # grad_u[m] is (du/dx, du/dy) approximated from edge m\n",
    "        grad_u_edges = (dv[:, 0] * e) / dist_sq\n",
    "        grad_v_edges = (dv[:, 1] * e) / dist_sq\n",
    "\n",
    "        # Aggregate edge-wise gradients back to nodes (Mean of neighbors)\n",
    "        node_grad_u = torch.zeros((num_nodes, 2), device=v.device).index_add_(0, idx_i, grad_u_edges)\n",
    "        node_grad_v = torch.zeros((num_nodes, 2), device=v.device).index_add_(0, idx_i, grad_v_edges)\n",
    "\n",
    "        # 3. Convective Term: (u · ∇)u\n",
    "        # For each node: u * du/dx + v * du/dy\n",
    "        conv_u = v[:, 0] * node_grad_u[:, 0] + v[:, 1] * node_grad_u[:, 1]\n",
    "        conv_v = v[:, 0] * node_grad_v[:, 0] + v[:, 1] * node_grad_v[:, 1]\n",
    "        convection = torch.stack([conv_u, conv_v], dim=1)\n",
    "\n",
    "        # 4. Viscous Term: ν ∇²u\n",
    "        # Laplacian approximated via the second-order finite difference on graphs\n",
    "        # L(u) ≈ Σ (u_j - u_i) / ||e_ij||^2\n",
    "        laplacian = torch.zeros_like(v)\n",
    "        laplacian.index_add_(0, idx_i, dv / dist_sq)\n",
    "\n",
    "\n",
    "        est_p = torch.ones(num_nodes)\n",
    "        while True:\n",
    "            dp = est_p[idx_j] - est_p[idx_i]\n",
    "\n",
    "            #  Pressure corrections: dp/dx/rho\n",
    "            grad_p_edges = (dp * e) / dist_sq\n",
    "\n",
    "            # Aggregate edge-wise gradients back to nodes (Mean of neighbors)\n",
    "            node_grad_p = torch.zeros((num_nodes, 2), device=v.device).index_add_(0, idx_i, grad_p_edges)\n",
    "\n",
    "            pressure_force = node_grad_p / self.rho\n",
    "\n",
    "            # 5. Predictor Step: Forward Euler\n",
    "            # v* = v + dt * ( - (u·∇)u + ν ∇²u )\n",
    "            dv_dt = -convection + self.nu * laplacian - pressure_force\n",
    "            v_next = v + self.dt * dv_dt\n",
    "\n",
    "            # v_next.backward()\n",
    "\n",
    "            dv_est = v_next[idx_j] - v_next[idx_i]  # [M, 2]\n",
    "            \n",
    "            # Local directional derivatives per edge\n",
    "            # grad_u[m] is (du/dx, du/dy) approximated from edge m\n",
    "            grad_u_est_edges = (dv_est[:, 0] * e) / dist_sq\n",
    "            grad_v_est_edges = (dv_est[:, 1] * e) / dist_sq\n",
    "\n",
    "            # Aggregate edge-wise gradients back to nodes (Mean of neighbors)\n",
    "            node_grad_u_est = torch.zeros((num_nodes, 2), device=v.device).index_add_(0, idx_i, grad_u_est_edges)\n",
    "            node_grad_v_est = torch.zeros((num_nodes, 2), device=v.device).index_add_(0, idx_i, grad_v_est_edges)\n",
    "\n",
    "            divergence = node_grad_u_est[:,0] + node_grad_v_est[:,1]\n",
    "            if torch.all(divergence<1e-4):\n",
    "                break\n",
    "            divergence.backward(est_p)\n",
    "            est_p += divergence.grad*self.relaxation_factor\n",
    "\n",
    "\n",
    "        return v_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb20642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FD(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dt: float = 0.01,\n",
    "        rho: float = 1.0,\n",
    "        nu: float = 0.01,\n",
    "        relaxation_factor: float = 0.2,\n",
    "        poisson_iters: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dt = dt\n",
    "        self.nu = nu\n",
    "        self.rho = rho\n",
    "        self.relaxation_factor = relaxation_factor\n",
    "        self.poisson_iters = poisson_iters\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Differential operators\n",
    "    # -------------------------------------------------------\n",
    "\n",
    "    def gradient(self, p, e, ij):\n",
    "        \"\"\"\n",
    "        ∇p at nodes from edge differences\n",
    "        \"\"\"\n",
    "        i, j = ij\n",
    "        dp = p[j] - p[i]                     # [M]\n",
    "        grad_e = dp[:, None] * e             # [M, 2]\n",
    "\n",
    "        grad = torch.zeros_like(p[:, None].repeat(1, 2))\n",
    "        grad.index_add_(0, i, grad_e)\n",
    "        grad.index_add_(0, j, -grad_e)\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def divergence(self, v, e, ij):\n",
    "        \"\"\"\n",
    "        ∇·v at nodes\n",
    "        \"\"\"\n",
    "        i, j = ij\n",
    "        dv = v[j] - v[i]                     # [M, 2]\n",
    "        flux = (dv * e).sum(dim=1)           # [M]\n",
    "\n",
    "        div = torch.zeros(v.shape[0], device=v.device)\n",
    "        div.index_add_(0, i, flux)\n",
    "        div.index_add_(0, j, -flux)\n",
    "\n",
    "        return div\n",
    "\n",
    "    def laplacian(self, v, e, ij):\n",
    "        \"\"\"\n",
    "        Vector Laplacian using edge diffusion\n",
    "        \"\"\"\n",
    "        i, j = ij\n",
    "        dv = v[j] - v[i]                     # [M, 2]\n",
    "        w = (e ** 2).sum(dim=1, keepdim=True)  # |e|^2\n",
    "\n",
    "        diff = dv / (w + 1e-8)\n",
    "\n",
    "        lap = torch.zeros_like(v)\n",
    "        lap.index_add_(0, i, diff)\n",
    "        lap.index_add_(0, j, -diff)\n",
    "\n",
    "        return lap\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Pressure Poisson solver (Jacobi)\n",
    "    # -------------------------------------------------------\n",
    "\n",
    "    def solve_pressure(self, rhs, e, ij):\n",
    "        p = torch.zeros_like(rhs)\n",
    "\n",
    "        i, j = ij\n",
    "        w = (e ** 2).sum(dim=1)\n",
    "        w = torch.clamp(w, min=1e-4)\n",
    "\n",
    "        # Precompute diagonal\n",
    "        diag = torch.zeros_like(p)\n",
    "        diag.index_add_(0, i, 1.0 / w)\n",
    "        diag.index_add_(0, j, 1.0 / w)\n",
    "        diag = torch.clamp(diag, min=1e-6)\n",
    "\n",
    "        for _ in range(self.poisson_iters):\n",
    "            dp = p[j] - p[i]\n",
    "            flux = dp / w\n",
    "\n",
    "            lap = torch.zeros_like(p)\n",
    "            lap.index_add_(0, i, flux)\n",
    "            lap.index_add_(0, j, -flux)\n",
    "\n",
    "            # Jacobi update\n",
    "            p = p + self.relaxation_factor * (rhs - lap) / diag\n",
    "\n",
    "            # Nullspace removal\n",
    "            p = p - p.mean()\n",
    "\n",
    "        return p\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # Main time step\n",
    "    # -------------------------------------------------------\n",
    "\n",
    "    def forward(self, v, e, ij):\n",
    "        \"\"\"\n",
    "        v: [N, 2] velocity\n",
    "        e: [M, 2] edge vectors\n",
    "        ij: [2, M] connectivity\n",
    "        \"\"\"\n",
    "\n",
    "        # ---------------------------\n",
    "        # Convection (edge upwind-ish)\n",
    "        # ---------------------------\n",
    "        i, j = ij\n",
    "        v_avg = 0.5 * (v[i] + v[j])\n",
    "        dv = v[j] - v[i]\n",
    "        conv_flux = (v_avg * e).sum(dim=1, keepdim=True) * dv\n",
    "\n",
    "        conv = torch.zeros_like(v)\n",
    "        conv.index_add_(0, i, conv_flux)\n",
    "        conv.index_add_(0, j, -conv_flux)\n",
    "\n",
    "        # ---------------------------\n",
    "        # Diffusion\n",
    "        # ---------------------------\n",
    "        diff = self.nu * self.laplacian(v, e, ij)\n",
    "\n",
    "        # ---------------------------\n",
    "        # Predictor step\n",
    "        # ---------------------------\n",
    "        v_star = v + self.dt * (-conv + diff)\n",
    "\n",
    "        # ---------------------------\n",
    "        # Pressure projection\n",
    "        # ---------------------------\n",
    "        div_v = self.divergence(v_star, e, ij)\n",
    "        rhs = (self.rho / self.dt) * div_v\n",
    "\n",
    "        p = self.solve_pressure(rhs, e, ij)\n",
    "\n",
    "        grad_p = self.gradient(p, e, ij)\n",
    "        v_new = v_star - (self.dt / self.rho) * grad_p\n",
    "\n",
    "        return v_new, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63d79d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergence before: 5.268e-09\n",
      "Divergence after : 1.211e-08\n",
      "Reduction factor : 2.299\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def make_unstructured_graph(n=200, radius=0.2):\n",
    "    \"\"\"\n",
    "    Generates:\n",
    "      nodes in [0,1]²\n",
    "      edges based on radius search\n",
    "    \"\"\"\n",
    "    pts = torch.rand(n, 2)\n",
    "\n",
    "    edges_i = []\n",
    "    edges_j = []\n",
    "    edges_e = []\n",
    "\n",
    "    for i in range(n):\n",
    "        diff = pts - pts[i]\n",
    "        dist = torch.norm(diff, dim=1)\n",
    "\n",
    "        nbrs = (dist < radius) & (dist > 1e-6)\n",
    "        for j in torch.where(nbrs)[0]:\n",
    "            edges_i.append(i)\n",
    "            edges_j.append(j.item())\n",
    "            edges_e.append(diff[j])\n",
    "\n",
    "    ij = torch.tensor([edges_i, edges_j], dtype=torch.long)\n",
    "    e = torch.stack(edges_e)\n",
    "\n",
    "    return pts, e, ij\n",
    "\n",
    "def initialize_velocity(x):\n",
    "    \"\"\"\n",
    "    Random velocity with bias\n",
    "    \"\"\"\n",
    "    v = torch.randn_like(x)\n",
    "    v[:, 0] += 1.0   # induce bulk flow\n",
    "    return v\n",
    "\n",
    "def divergence_norm(model, v, e, ij):\n",
    "    div = model.divergence(v, e, ij)\n",
    "    return torch.norm(div) / v.shape[0]\n",
    "\n",
    "# from fd_model import FD   # or wherever your FD class lives\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Graph\n",
    "x, e, ij = make_unstructured_graph(n=300, radius=0.15)\n",
    "\n",
    "# Model\n",
    "model = FD(\n",
    "    dt=0.01,\n",
    "    nu=0.01,\n",
    "    rho=1.0,\n",
    "    poisson_iters=40,\n",
    "    relaxation_factor=0.25,\n",
    ")\n",
    "\n",
    "# Velocity\n",
    "v0 = initialize_velocity(x)\n",
    "v0.requires_grad_(True)\n",
    "\n",
    "# Before projection\n",
    "div0 = divergence_norm(model, v0, e, ij)\n",
    "\n",
    "# Step\n",
    "v1, p = model(v0, e, ij)\n",
    "\n",
    "# After projection\n",
    "div1 = divergence_norm(model, v1, e, ij)\n",
    "\n",
    "print(f\"Divergence before: {div0.item():.3e}\")\n",
    "print(f\"Divergence after : {div1.item():.3e}\")\n",
    "print(f\"Reduction factor : {(div1/div0).item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c65b6505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 00: div=1.211e-08, KE=2.073e+01\n",
      "step 05: div=7.872e-01, KE=1.116e+17\n",
      "step 10: div=nan, KE=nan\n",
      "step 15: div=nan, KE=nan\n"
     ]
    }
   ],
   "source": [
    "v = v0.detach()\n",
    "for step in range(20):\n",
    "    v, p = model(v, e, ij)\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        div = divergence_norm(model, v, e, ij)\n",
    "        ke = torch.mean(torch.sum(v**2, dim=1))\n",
    "        print(f\"step {step:02d}: div={div:.3e}, KE={ke:.3e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
